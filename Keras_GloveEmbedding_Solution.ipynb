{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe Embeddings using Keras\n",
    "## This notebook outlines the concepts of using pre-trained GloVe Embeddings using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vtDkfRxFBtJS"
   },
   "source": [
    "### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I6sgvWRvB0IP"
   },
   "outputs": [],
   "source": [
    "from numpy import array, asarray, zeros\n",
    "from tensorflow.keras.preprocessing.text import one_hot, Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FJLFlrVWB4c8"
   },
   "source": [
    "### Define the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eWlkStItB_jc"
   },
   "outputs": [],
   "source": [
    "docs = ['Well 2 done!',\n",
    "        'Good work',\n",
    "        'Great effort',\n",
    "        'nice work',\n",
    "        'Excellent!',\n",
    "        'Weak',\n",
    "        'Poor effort!',\n",
    "        'not good',\n",
    "        'poor work',\n",
    "        'Could have done better.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w4pge57YCBxH"
   },
   "source": [
    "### Define the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0h1CPBUGCPqg"
   },
   "outputs": [],
   "source": [
    "labels = array([1,1,1,1,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lupemgx-CU4A"
   },
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-2Dgp1GFCdtB",
    "outputId": "4ac3293e-58a9-4469-80ed-c8b9cc524163"
   },
   "outputs": [],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(docs)\n",
    "vocab_size = len(t.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "91ot346xlbUM"
   },
   "source": [
    "### Integer encode the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_QHUVOjmleB_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 7, 2], [3, 1], [8, 4], [9, 1], [10], [11], [5, 4], [12, 3], [5, 1], [13, 14, 2, 15]]\n"
     ]
    }
   ],
   "source": [
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(docs)\n",
    "print(encoded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XPbuEu2KCyx3"
   },
   "source": [
    "### Padding documents to a desired max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "TjmfmdRtC8fE",
    "outputId": "5e5d70af-63ea-4322-8384-e84e9c4d87ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  2  0  0]\n",
      " [ 3  1  0  0]\n",
      " [ 7  4  0  0]\n",
      " [ 8  1  0  0]\n",
      " [ 9  0  0  0]\n",
      " [10  0  0  0]\n",
      " [ 5  4  0  0]\n",
      " [11  3  0  0]\n",
      " [ 5  1  0  0]\n",
      " [12 13  2 14]]\n"
     ]
    }
   ],
   "source": [
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZzMe99uzlqaY"
   },
   "source": [
    "### Load the GloVe Embedding into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vbm_lpUXlugT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      ",\n",
      ".\n",
      "of\n",
      "to\n",
      "and\n",
      "in\n",
      "a\n",
      "\"\n",
      "'s\n",
      "for\n",
      "-\n",
      "that\n",
      "on\n",
      "is\n",
      "was\n",
      "said\n",
      "with\n",
      "he\n",
      "as\n",
      "it\n",
      "by\n",
      "at\n",
      "(\n",
      ")\n",
      "from\n",
      "his\n",
      "''\n",
      "``\n",
      "an\n",
      "be\n",
      "has\n",
      "are\n",
      "have\n",
      "but\n",
      "were\n",
      "not\n",
      "this\n",
      "who\n",
      "they\n",
      "had\n",
      "i\n",
      "which\n",
      "will\n",
      "their\n",
      ":\n",
      "or\n",
      "its\n",
      "one\n",
      "after\n",
      "new\n",
      "been\n",
      "also\n",
      "we\n",
      "would\n",
      "two\n",
      "more\n",
      "'\n",
      "first\n",
      "about\n",
      "up\n",
      "when\n",
      "year\n",
      "there\n",
      "all\n",
      "--\n",
      "out\n",
      "she\n",
      "other\n",
      "people\n",
      "n't\n",
      "her\n",
      "percent\n",
      "than\n",
      "over\n",
      "into\n",
      "last\n",
      "some\n",
      "government\n",
      "time\n",
      "$\n",
      "you\n",
      "years\n",
      "if\n",
      "no\n",
      "world\n",
      "can\n",
      "three\n",
      "do\n",
      ";\n",
      "president\n",
      "only\n",
      "state\n",
      "million\n",
      "could\n",
      "us\n",
      "most\n",
      "_\n",
      "against\n",
      "u.s.\n",
      "so\n",
      "them\n",
      "what\n",
      "him\n",
      "united\n",
      "during\n",
      "before\n",
      "may\n",
      "since\n",
      "many\n",
      "while\n",
      "where\n",
      "states\n",
      "because\n",
      "now\n",
      "city\n",
      "made\n",
      "like\n",
      "between\n",
      "did\n",
      "just\n",
      "national\n",
      "day\n",
      "country\n",
      "under\n",
      "such\n",
      "second\n",
      "then\n",
      "company\n",
      "group\n",
      "any\n",
      "through\n",
      "china\n",
      "four\n",
      "being\n",
      "down\n",
      "war\n",
      "back\n",
      "off\n",
      "south\n",
      "american\n",
      "minister\n",
      "police\n",
      "well\n",
      "including\n",
      "team\n",
      "international\n",
      "week\n",
      "officials\n",
      "still\n",
      "both\n",
      "even\n",
      "high\n",
      "part\n",
      "told\n",
      "those\n",
      "end\n",
      "former\n",
      "these\n",
      "make\n",
      "billion\n",
      "work\n",
      "our\n",
      "home\n",
      "school\n",
      "party\n",
      "house\n",
      "old\n",
      "later\n",
      "get\n",
      "another\n",
      "tuesday\n",
      "news\n",
      "long\n",
      "five\n",
      "called\n",
      "1\n",
      "wednesday\n",
      "military\n",
      "way\n",
      "used\n",
      "much\n",
      "next\n",
      "monday\n",
      "thursday\n",
      "friday\n",
      "game\n",
      "here\n",
      "?\n",
      "should\n",
      "take\n",
      "very\n",
      "my\n",
      "north\n",
      "security\n",
      "season\n",
      "york\n",
      "how\n",
      "public\n",
      "early\n",
      "according\n",
      "several\n",
      "court\n",
      "say\n",
      "around\n",
      "foreign\n",
      "10\n",
      "until\n",
      "set\n",
      "political\n",
      "says\n",
      "market\n",
      "however\n",
      "family\n",
      "life\n",
      "same\n",
      "general\n",
      "â€“\n",
      "left\n",
      "good\n",
      "top\n",
      "university\n",
      "going\n",
      "number\n",
      "major\n",
      "known\n",
      "points\n",
      "won\n",
      "six\n",
      "month\n",
      "dollars\n",
      "bank\n",
      "2\n",
      "iraq\n",
      "use\n",
      "members\n",
      "each\n",
      "area\n",
      "found\n",
      "official\n",
      "sunday\n",
      "place\n",
      "go\n",
      "based\n",
      "among\n",
      "third\n",
      "times\n",
      "took\n",
      "right\n",
      "days\n",
      "local\n",
      "economic\n",
      "countries\n",
      "see\n",
      "best\n",
      "report\n",
      "killed\n",
      "held\n",
      "business\n",
      "west\n",
      "does\n",
      "own\n",
      "%\n",
      "came\n",
      "law\n",
      "months\n",
      "women\n",
      "'re\n",
      "power\n",
      "think\n",
      "service\n",
      "children\n",
      "bush\n",
      "show\n",
      "/\n",
      "help\n",
      "chief\n",
      "saturday\n",
      "system\n",
      "john\n",
      "support\n",
      "series\n",
      "play\n",
      "office\n",
      "following\n",
      "me\n",
      "meeting\n",
      "expected\n",
      "late\n",
      "washington\n",
      "games\n",
      "european\n",
      "league\n",
      "reported\n",
      "final\n",
      "added\n",
      "without\n",
      "british\n",
      "white\n",
      "history\n",
      "man\n",
      "men\n",
      "became\n",
      "want\n",
      "march\n",
      "case\n",
      "few\n",
      "run\n",
      "money\n",
      "began\n",
      "open\n",
      "name\n",
      "trade\n",
      "center\n",
      "3\n",
      "israel\n",
      "oil\n",
      "too\n",
      "al\n",
      "film\n",
      "win\n",
      "led\n",
      "east\n",
      "central\n",
      "20\n",
      "air\n",
      "come\n",
      "chinese\n",
      "town\n",
      "leader\n",
      "army\n",
      "line\n",
      "never\n",
      "little\n",
      "played\n",
      "prime\n",
      "death\n",
      "companies\n",
      "least\n",
      "put\n",
      "forces\n",
      "past\n",
      "de\n",
      "half\n",
      "june\n",
      "saying\n",
      "know\n",
      "federal\n",
      "french\n",
      "peace\n",
      "earlier\n",
      "capital\n",
      "force\n",
      "great\n",
      "union\n",
      "near\n",
      "released\n",
      "small\n",
      "department\n",
      "every\n",
      "health\n",
      "japan\n",
      "head\n",
      "ago\n",
      "night\n",
      "big\n",
      "cup\n",
      "election\n",
      "region\n",
      "director\n",
      "talks\n",
      "program\n",
      "far\n",
      "today\n",
      "statement\n",
      "july\n",
      "although\n",
      "district\n",
      "again\n",
      "born\n",
      "development\n",
      "leaders\n",
      "council\n",
      "close\n",
      "record\n",
      "along\n",
      "county\n",
      "france\n",
      "went\n",
      "point\n",
      "must\n",
      "spokesman\n",
      "your\n",
      "member\n",
      "plan\n",
      "financial\n",
      "april\n",
      "recent\n",
      "campaign\n",
      "become\n",
      "troops\n",
      "whether\n",
      "lost\n",
      "music\n",
      "15\n",
      "got\n",
      "israeli\n",
      "30\n",
      "need\n",
      "4\n",
      "lead\n",
      "already\n",
      "russia\n",
      "though\n",
      "might\n",
      "free\n",
      "hit\n",
      "rights\n",
      "11\n",
      "information\n",
      "away\n",
      "12\n",
      "5\n",
      "others\n",
      "control\n",
      "within\n",
      "large\n",
      "economy\n",
      "press\n",
      "agency\n",
      "water\n",
      "died\n",
      "career\n",
      "making\n",
      "...\n",
      "deal\n",
      "attack\n",
      "side\n",
      "seven\n",
      "better\n",
      "less\n",
      "september\n",
      "once\n",
      "clinton\n",
      "main\n",
      "due\n",
      "committee\n",
      "building\n",
      "conference\n",
      "club\n",
      "january\n",
      "decision\n",
      "stock\n",
      "america\n",
      "given\n",
      "give\n",
      "often\n",
      "announced\n",
      "television\n",
      "industry\n",
      "order\n",
      "young\n",
      "'ve\n",
      "palestinian\n",
      "age\n",
      "start\n",
      "administration\n",
      "russian\n",
      "prices\n",
      "round\n",
      "december\n",
      "nations\n",
      "'m\n",
      "human\n",
      "india\n",
      "defense\n",
      "asked\n",
      "total\n",
      "october\n",
      "players\n",
      "bill\n",
      "important\n",
      "southern\n",
      "move\n",
      "fire\n",
      "population\n",
      "rose\n",
      "november\n",
      "include\n",
      "further\n",
      "nuclear\n",
      "street\n",
      "taken\n",
      "media\n",
      "different\n",
      "issue\n",
      "received\n",
      "secretary\n",
      "return\n",
      "college\n",
      "working\n",
      "community\n",
      "eight\n",
      "groups\n",
      "despite\n",
      "level\n",
      "largest\n",
      "whose\n",
      "attacks\n",
      "germany\n",
      "august\n",
      "change\n",
      "church\n",
      "nation\n",
      "german\n",
      "station\n",
      "london\n",
      "weeks\n",
      "having\n",
      "18\n",
      "research\n",
      "black\n",
      "services\n",
      "story\n",
      "6\n",
      "europe\n",
      "sales\n",
      "policy\n",
      "visit\n",
      "northern\n",
      "lot\n",
      "across\n",
      "per\n",
      "current\n",
      "board\n",
      "football\n",
      "ministry\n",
      "workers\n",
      "vote\n",
      "book\n",
      "fell\n",
      "seen\n",
      "role\n",
      "students\n",
      "shares\n",
      "iran\n",
      "process\n",
      "agreement\n",
      "quarter\n",
      "full\n",
      "match\n",
      "started\n",
      "growth\n",
      "yet\n",
      "moved\n",
      "possible\n",
      "western\n",
      "special\n",
      "100\n",
      "plans\n",
      "interest\n",
      "behind\n",
      "strong\n",
      "england\n",
      "named\n",
      "food\n",
      "period\n",
      "real\n",
      "authorities\n",
      "car\n",
      "term\n",
      "rate\n",
      "race\n",
      "nearly\n",
      "korea\n",
      "enough\n",
      "site\n",
      "opposition\n",
      "keep\n",
      "25\n",
      "call\n",
      "future\n",
      "taking\n",
      "island\n",
      "2008\n",
      "2006\n",
      "road\n",
      "outside\n",
      "really\n",
      "century\n",
      "democratic\n",
      "almost\n",
      "single\n",
      "share\n",
      "leading\n",
      "trying\n",
      "find\n",
      "album\n",
      "senior\n",
      "minutes\n",
      "together\n",
      "congress\n",
      "index\n",
      "australia\n",
      "results\n",
      "hard\n",
      "hours\n",
      "land\n",
      "action\n",
      "higher\n",
      "field\n",
      "cut\n",
      "coach\n",
      "elections\n",
      "san\n",
      "issues\n",
      "executive\n",
      "february\n",
      "production\n",
      "areas\n",
      "river\n",
      "face\n",
      "using\n",
      "japanese\n",
      "province\n",
      "park\n",
      "price\n",
      "commission\n",
      "california\n",
      "father\n",
      "son\n",
      "education\n",
      "7\n",
      "village\n",
      "energy\n",
      "shot\n",
      "short\n",
      "africa\n",
      "key\n",
      "red\n",
      "association\n",
      "average\n",
      "pay\n",
      "exchange\n",
      "eu\n",
      "something\n",
      "gave\n",
      "likely\n",
      "player\n",
      "george\n",
      "2007\n",
      "victory\n",
      "8\n",
      "low\n",
      "things\n",
      "2010\n",
      "pakistan\n",
      "14\n",
      "post\n",
      "social\n",
      "continue\n",
      "ever\n",
      "look\n",
      "chairman\n",
      "job\n",
      "2000\n",
      "soldiers\n",
      "able\n",
      "parliament\n",
      "front\n",
      "himself\n",
      "problems\n",
      "private\n",
      "lower\n",
      "list\n",
      "built\n",
      "13\n",
      "efforts\n",
      "dollar\n",
      "miles\n",
      "included\n",
      "radio\n",
      "live\n",
      "form\n",
      "david\n",
      "african\n",
      "increase\n",
      "reports\n",
      "sent\n",
      "fourth\n",
      "always\n",
      "king\n",
      "50\n",
      "tax\n",
      "taiwan\n",
      "britain\n",
      "16\n",
      "playing\n",
      "title\n",
      "middle\n",
      "meet\n",
      "global\n",
      "wife\n",
      "2009\n",
      "position\n",
      "located\n",
      "clear\n",
      "ahead\n",
      "2004\n",
      "2005\n",
      "iraqi\n",
      "english\n",
      "result\n",
      "release\n",
      "violence\n",
      "goal\n",
      "project\n",
      "closed\n",
      "border\n",
      "body\n",
      "soon\n",
      "crisis\n",
      "division\n",
      "&amp;\n",
      "served\n",
      "tour\n",
      "hospital\n",
      "kong\n",
      "test\n",
      "hong\n",
      "u.n.\n",
      "inc.\n",
      "technology\n",
      "believe\n",
      "organization\n",
      "published\n",
      "weapons\n",
      "agreed\n",
      "why\n",
      "nine\n",
      "summer\n",
      "wanted\n",
      "republican\n",
      "act\n",
      "recently\n",
      "texas\n",
      "course\n",
      "problem\n",
      "senate\n",
      "medical\n",
      "un\n",
      "done\n",
      "reached\n",
      "star\n",
      "continued\n",
      "investors\n",
      "living\n",
      "care\n",
      "signed\n",
      "17\n",
      "art\n",
      "provide\n",
      "worked\n",
      "presidential\n",
      "gold\n",
      "obama\n",
      "morning\n",
      "dead\n",
      "opened\n",
      "'ll\n",
      "event\n",
      "previous\n",
      "cost\n",
      "instead\n",
      "canada\n",
      "band\n",
      "teams\n",
      "daily\n",
      "2001\n",
      "available\n",
      "drug\n",
      "coming\n",
      "2003\n",
      "investment\n",
      "â€™s\n",
      "michael\n",
      "civil\n",
      "woman\n",
      "training\n",
      "appeared\n",
      "9\n",
      "involved\n",
      "indian\n",
      "similar\n",
      "situation\n",
      "24\n",
      "los\n",
      "running\n",
      "fighting\n",
      "mark\n",
      "40\n",
      "trial\n",
      "hold\n",
      "australian\n",
      "thought\n",
      "!\n",
      "study\n",
      "fall\n",
      "mother\n",
      "met\n",
      "relations\n",
      "anti\n",
      "2002\n",
      "song\n",
      "popular\n",
      "base\n",
      "tv\n",
      "ground\n",
      "markets\n",
      "ii\n",
      "newspaper\n",
      "staff\n",
      "saw\n",
      "hand\n",
      "hope\n",
      "operations\n",
      "pressure\n",
      "americans\n",
      "eastern\n",
      "st.\n",
      "legal\n",
      "asia\n",
      "budget\n",
      "returned\n",
      "considered\n",
      "love\n",
      "wrote\n",
      "stop\n",
      "fight\n",
      "currently\n",
      "charges\n",
      "try\n",
      "aid\n",
      "ended\n",
      "management\n",
      "brought\n",
      "cases\n",
      "decided\n",
      "failed\n",
      "network\n",
      "works\n",
      "gas\n",
      "turned\n",
      "fact\n",
      "vice\n",
      "ca\n",
      "mexico\n",
      "trading\n",
      "especially\n",
      "reporters\n",
      "afghanistan\n",
      "common\n",
      "looking\n",
      "space\n",
      "rates\n",
      "manager\n",
      "loss\n",
      "2011\n",
      "justice\n",
      "thousands\n",
      "james\n",
      "rather\n",
      "fund\n",
      "thing\n",
      "republic\n",
      "opening\n",
      "accused\n",
      "winning\n",
      "scored\n",
      "championship\n",
      "example\n",
      "getting\n",
      "biggest\n",
      "performance\n",
      "sports\n",
      "1998\n",
      "let\n",
      "allowed\n",
      "schools\n",
      "means\n",
      "turn\n",
      "leave\n",
      "no.\n",
      "robert\n",
      "personal\n",
      "stocks\n",
      "showed\n",
      "light\n",
      "arrested\n",
      "person\n",
      "either\n",
      "offer\n",
      "majority\n",
      "battle\n",
      "19\n",
      "class\n",
      "evidence\n",
      "makes\n",
      "society\n",
      "products\n",
      "regional\n",
      "needed\n",
      "stage\n",
      "am\n",
      "doing\n",
      "families\n",
      "construction\n",
      "various\n",
      "1996\n",
      "sold\n",
      "independent\n",
      "kind\n",
      "airport\n",
      "paul\n",
      "judge\n",
      "internet\n",
      "movement\n",
      "room\n",
      "followed\n",
      "original\n",
      "angeles\n",
      "italy\n",
      "`\n",
      "data\n",
      "comes\n",
      "parties\n",
      "nothing\n",
      "sea\n",
      "bring\n",
      "2012\n",
      "annual\n",
      "officer\n",
      "beijing\n",
      "present\n",
      "remain\n",
      "nato\n",
      "1999\n",
      "22\n",
      "remains\n",
      "allow\n",
      "florida\n",
      "computer\n",
      "21\n",
      "contract\n",
      "coast\n",
      "created\n",
      "demand\n",
      "operation\n",
      "events\n",
      "islamic\n",
      "beat\n",
      "analysts\n",
      "interview\n",
      "helped\n",
      "child\n",
      "probably\n",
      "spent\n",
      "asian\n",
      "effort\n",
      "cooperation\n",
      "shows\n",
      "calls\n",
      "investigation\n",
      "lives\n",
      "video\n",
      "yen\n",
      "runs\n",
      "tried\n",
      "bad\n",
      "described\n",
      "1994\n",
      "toward\n",
      "written\n",
      "throughout\n",
      "established\n",
      "mission\n",
      "associated\n",
      "buy\n",
      "growing\n",
      "green\n",
      "forward\n",
      "competition\n",
      "poor\n",
      "latest\n",
      "banks\n",
      "question\n",
      "1997\n",
      "prison\n",
      "feel\n",
      "attention\n",
      "themselves\n",
      "firm\n",
      "injured\n",
      "itself\n",
      "governor\n",
      "movie\n",
      "range\n",
      "cross\n",
      "track\n",
      "programs\n",
      "1995\n",
      "forced\n",
      "includes\n",
      "difficult\n",
      "produced\n",
      "wall\n",
      "rebels\n",
      "income\n",
      "corp.\n",
      "chance\n",
      "elected\n",
      "23\n",
      "reach\n",
      "adding\n",
      "species\n",
      "wants\n",
      "finished\n",
      "rise\n",
      "killing\n",
      "spain\n",
      "joined\n",
      "italian\n",
      "language\n",
      "rest\n",
      "serious\n",
      "paris\n",
      "tournament\n",
      "officers\n",
      "inside\n",
      "scheduled\n",
      "immediately\n",
      "increased\n",
      "brown\n",
      "remained\n",
      "parts\n",
      "success\n",
      "changes\n",
      "la\n",
      "residents\n",
      "meanwhile\n",
      "net\n",
      "sides\n",
      "jobs\n",
      "hall\n",
      "believed\n",
      "olympic\n",
      "deputy\n",
      "records\n",
      "heart\n",
      "champion\n",
      "award\n",
      "planned\n",
      "version\n",
      "grand\n",
      "institute\n",
      "step\n",
      "democrats\n",
      "rule\n",
      "labor\n",
      "above\n",
      "summit\n",
      "sometimes\n",
      "addition\n",
      "raised\n",
      "william\n",
      "needs\n",
      "26\n",
      "talk\n",
      "longer\n",
      "terms\n",
      "rules\n",
      "ruling\n",
      "joint\n",
      "ball\n",
      "beginning\n",
      "sure\n",
      "28\n",
      "stay\n",
      "safety\n",
      "worth\n",
      "charge\n",
      "korean\n",
      "begin\n",
      "arab\n",
      "27\n",
      "friends\n",
      "anything\n",
      "atlanta\n",
      "caused\n",
      "sources\n",
      "sign\n",
      "issued\n",
      "armed\n",
      "cents\n",
      "funds\n",
      "claimed\n",
      "heavy\n",
      "noted\n",
      "parents\n",
      "spending\n",
      "e\n",
      "related\n",
      "offered\n",
      "particularly\n",
      "aircraft\n",
      "whole\n",
      "60\n",
      "authority\n",
      "risk\n",
      "cannot\n",
      "matter\n",
      "science\n",
      "access\n",
      "boston\n",
      "conditions\n",
      "details\n",
      "coalition\n",
      "compared\n",
      "lee\n",
      "break\n",
      "turkey\n",
      "daughter\n",
      "natural\n",
      "museum\n",
      "strike\n",
      "style\n",
      "paid\n",
      "rock\n",
      "costs\n",
      "view\n",
      "usually\n",
      "spanish\n",
      "royal\n",
      "travel\n",
      "takes\n",
      "books\n",
      "smith\n",
      "chicago\n",
      "systems\n",
      "arrived\n",
      "hundreds\n",
      "'d\n",
      "hour\n",
      "response\n",
      "developed\n",
      "jones\n",
      "potential\n",
      "cause\n",
      "value\n",
      "idea\n",
      "thomas\n",
      "&\n",
      "professional\n",
      "domestic\n",
      "credit\n",
      "changed\n",
      "gaza\n",
      "married\n",
      "co.\n",
      "launched\n",
      "web\n",
      "p.m.\n",
      "muslim\n",
      "source\n",
      "everything\n",
      "weekend\n",
      "camp\n",
      "quickly\n",
      "owned\n",
      "finance\n",
      "palestinians\n",
      "eventually\n",
      "measures\n",
      "cities\n",
      "afp\n",
      "blue\n",
      "richard\n",
      "starting\n",
      "ready\n",
      "plant\n",
      "build\n",
      "designed\n",
      "certain\n",
      "voters\n",
      "modern\n",
      "fans\n",
      "commercial\n",
      "bid\n",
      "provided\n",
      "constitution\n",
      "dropped\n",
      "brother\n",
      "canadian\n",
      "drive\n",
      "goals\n",
      "negotiations\n",
      "affairs\n",
      "unit\n",
      "questions\n",
      "significant\n",
      "create\n",
      "bomb\n",
      "warned\n",
      "religious\n",
      "minute\n",
      "figures\n",
      "victims\n",
      "condition\n",
      "activities\n",
      "upon\n",
      "leaving\n",
      "experience\n",
      "=\n",
      "attorney\n",
      "standard\n",
      "proposed\n",
      "intelligence\n",
      "giving\n",
      "hotel\n",
      "finally\n",
      "magazine\n",
      "whom\n",
      "experts\n",
      "moving\n",
      "quoted\n",
      "baghdad\n",
      "carried\n",
      "feet\n",
      "candidate\n",
      "fifth\n",
      "highest\n",
      "lake\n",
      "employees\n",
      "sell\n",
      "pacific\n",
      "31\n",
      "mostly\n",
      "reason\n",
      "flight\n",
      "square\n",
      "overall\n",
      "1993\n",
      "design\n",
      "passed\n",
      "focus\n",
      "bay\n",
      "dlrs\n",
      "date\n",
      "letter\n",
      "1992\n",
      "wide\n",
      "effect\n",
      "charged\n",
      "29\n",
      "phone\n",
      "figure\n",
      "attempt\n",
      "claims\n",
      "below\n",
      "profit\n",
      "200\n",
      "industrial\n",
      "zealand\n",
      "estimated\n",
      "traditional\n",
      "size\n",
      "practice\n",
      "cars\n",
      "double\n",
      "2013\n",
      "pass\n",
      "hands\n",
      "professor\n",
      "student\n",
      "concerns\n",
      "refused\n",
      "sector\n",
      "review\n",
      "homes\n",
      "disease\n",
      "kept\n",
      "terrorism\n",
      "online\n",
      "speech\n",
      "peter\n",
      "culture\n",
      "reform\n",
      "founded\n",
      "ordered\n",
      "successful\n",
      "arms\n",
      "charles\n",
      "conflict\n",
      "limited\n",
      "material\n",
      "trip\n",
      "property\n",
      "paper\n",
      "threat\n",
      "seeking\n",
      "concern\n",
      "confirmed\n",
      "1991\n",
      "plane\n",
      "route\n",
      "completed\n",
      "jewish\n",
      "williams\n",
      "someone\n",
      "hill\n",
      "comment\n",
      "numbers\n",
      "ireland\n",
      "taliban\n",
      "huge\n",
      "johnson\n",
      "mayor\n",
      "husband\n",
      "â€”\n",
      "mass\n",
      "lines\n",
      "premier\n",
      "soviet\n",
      "cover\n",
      "couple\n",
      "positive\n",
      "complete\n",
      "non\n",
      "republicans\n",
      "mail\n",
      "crime\n",
      "moscow\n",
      "brazil\n",
      "0\n",
      "dr.\n",
      "kilometers\n",
      "stand\n",
      "formed\n",
      "seems\n",
      "felt\n",
      "separate\n",
      "amid\n",
      "stadium\n",
      "singapore\n",
      "speaking\n",
      "hopes\n",
      "leadership\n",
      "emergency\n",
      "declined\n",
      "treatment\n",
      "cabinet\n",
      "tell\n",
      "straight\n",
      "tokyo\n",
      "winner\n",
      "ban\n",
      "session\n",
      "serve\n",
      "progress\n",
      "wo\n",
      "ship\n",
      "projects\n",
      "independence\n",
      "appointed\n",
      "words\n",
      "recorded\n",
      "terrorist\n",
      "christian\n",
      "politics\n",
      "studies\n",
      "sense\n",
      "plays\n",
      "militants\n",
      "holding\n",
      "500\n",
      "regular\n",
      "required\n",
      "lawyer\n",
      "word\n",
      "debt\n",
      "guard\n",
      "wounded\n",
      "candidates\n",
      "assembly\n",
      "expressed\n",
      "character\n",
      "pro\n",
      "fuel\n",
      "martin\n",
      "supreme\n",
      "broke\n",
      "ministers\n",
      "everyone\n",
      "actually\n",
      "equipment\n",
      "additional\n",
      "sept.\n",
      "denied\n",
      "â€œ\n",
      "friend\n",
      "features\n",
      "levels\n",
      "approved\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x9d in position 2273: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-fbca0a9b54da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'glove.6B.50d.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# f = open('glove.840B.300d.txt')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mword\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sansk\\appdata\\local\\programs\\python\\python37\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x9d in position 2273: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('glove.6B.50d.txt')\n",
    "# f = open('glove.840B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    print(word)\n",
    "    coefs = asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-SCPjrOxlz75"
   },
   "source": [
    "### Create Embedding matrix for the custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hmlUeRzXl4oS"
   },
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = zeros((vocab_size, 50))\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ok8-mhucmCma"
   },
   "source": [
    "### Define the Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XzVFUfaNmE_Q"
   },
   "outputs": [],
   "source": [
    "e = Embedding(vocab_size, 50, weights=[embedding_matrix], input_length=4, trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NGkgwJr2DQSh"
   },
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pukPZKfxDUR_"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(e)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0owgnND9DduT"
   },
   "source": [
    "### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wGGEBN7UDhCM"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hg94_gK1DnL8"
   },
   "source": [
    "### Summarize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "nZh9jScxDrm6",
    "outputId": "081a7dbe-e3c0-4fff-c935-f763cbb7f0ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 4, 50)             750       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                4020      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 4,991\n",
      "Trainable params: 4,241\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mz6KK_9tDxrA"
   },
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dfd1v7LAD_dM",
    "outputId": "7a37639e-aa92-4be2-9f55-10ef0a99d301"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10 samples\n",
      "Epoch 1/50\n",
      "10/10 [==============================] - 0s 601us/sample - loss: 0.1733 - acc: 0.9000\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 300us/sample - loss: 0.1724 - acc: 0.9000\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 350us/sample - loss: 0.1715 - acc: 0.9000\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 299us/sample - loss: 0.1706 - acc: 0.9000\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 200us/sample - loss: 0.1698 - acc: 0.9000\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 300us/sample - loss: 0.1690 - acc: 0.9000\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 200us/sample - loss: 0.1682 - acc: 0.9000\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 253us/sample - loss: 0.1675 - acc: 0.9000\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 300us/sample - loss: 0.1668 - acc: 0.9000\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 300us/sample - loss: 0.1661 - acc: 0.9000\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 300us/sample - loss: 0.1654 - acc: 0.9000\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s 300us/sample - loss: 0.1648 - acc: 0.9000\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s 400us/sample - loss: 0.1641 - acc: 0.9000\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s 300us/sample - loss: 0.1635 - acc: 0.9000\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s 192us/sample - loss: 0.1630 - acc: 0.9000\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s 297us/sample - loss: 0.1624 - acc: 0.9000\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s 301us/sample - loss: 0.1619 - acc: 0.9000\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s 224us/sample - loss: 0.1613 - acc: 0.9000\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s 203us/sample - loss: 0.1608 - acc: 0.9000\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s 407us/sample - loss: 0.1603 - acc: 0.9000\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 0s 304us/sample - loss: 0.1598 - acc: 0.9000\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s 317us/sample - loss: 0.1594 - acc: 0.9000\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s 496us/sample - loss: 0.1589 - acc: 0.9000\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s 300us/sample - loss: 0.1585 - acc: 0.9000\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s 196us/sample - loss: 0.1580 - acc: 0.9000\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s 300us/sample - loss: 0.1576 - acc: 0.9000\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s 404us/sample - loss: 0.1572 - acc: 0.9000\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s 300us/sample - loss: 0.1568 - acc: 0.9000\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s 233us/sample - loss: 0.1564 - acc: 0.9000\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s 397us/sample - loss: 0.1560 - acc: 0.9000\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s 304us/sample - loss: 0.1556 - acc: 0.9000\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s 329us/sample - loss: 0.1553 - acc: 0.9000\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s 398us/sample - loss: 0.1549 - acc: 0.9000\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s 300us/sample - loss: 0.1545 - acc: 0.9000\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s 296us/sample - loss: 0.1542 - acc: 0.9000\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s 200us/sample - loss: 0.1539 - acc: 0.9000\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s 199us/sample - loss: 0.1536 - acc: 0.9000\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s 297us/sample - loss: 0.1533 - acc: 0.9000\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s 196us/sample - loss: 0.1530 - acc: 0.9000\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s 192us/sample - loss: 0.1527 - acc: 0.9000\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 0s 239us/sample - loss: 0.1524 - acc: 0.9000\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s 400us/sample - loss: 0.1521 - acc: 0.9000\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s 196us/sample - loss: 0.1518 - acc: 0.9000\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s 285us/sample - loss: 0.1516 - acc: 0.9000\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s 189us/sample - loss: 0.1513 - acc: 0.9000\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s 400us/sample - loss: 0.1511 - acc: 0.9000\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s 197us/sample - loss: 0.1508 - acc: 0.9000\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s 404us/sample - loss: 0.1506 - acc: 0.9000\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s 300us/sample - loss: 0.1504 - acc: 0.9000\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s 300us/sample - loss: 0.1501 - acc: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2013a8c0108>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_docs, labels, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p45EWai3EBe0"
   },
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4OwzvLq9EHJQ",
    "outputId": "53e0a478-c991-49aa-8806-934adf8ef4f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.999998\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6uVmvtf0I5WY"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Keras-OwnEmbedding-Solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
