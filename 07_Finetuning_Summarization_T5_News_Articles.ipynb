{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Finetuning_Summarization_T5_News_Articles.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhqFW_p_5GVY"
      },
      "source": [
        "# Finetuning Summarization on a T5 model\n",
        "## This notebook outlines the Finetuning of a News Summarization dataset on a T5 model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Gc1GpEw5rv5"
      },
      "source": [
        "### Install the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0SH8UrJ3MIB",
        "outputId": "a58b1fc7-711a-4148-fa9d-1a035f20ade6"
      },
      "source": [
        "!pip install -q sentencepiece transformers torch rich[jupyter]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.2MB 26.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.3MB 32.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 58.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3MB 51.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 901kB 40.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.9MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZZpD11q5xtf"
      },
      "source": [
        "### Import the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5tLIjxx3dOV"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9fnSXLM3kn3"
      },
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# rich: for a better display on terminal\n",
        "from rich.table import Column, Table\n",
        "from rich import box\n",
        "from rich.console import Console\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MULGR4Um6YBD"
      },
      "source": [
        "### Define a rich console logger"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxcEU2N13oXM"
      },
      "source": [
        "console = Console(record=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CU9Zm9UM6b_b"
      },
      "source": [
        "### To display dataframe in ASCII format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgjRMx_g3rr_"
      },
      "source": [
        "def display_df(df):\n",
        "    \"\"\"display dataframe in ASCII format\"\"\"\n",
        "\n",
        "    console = Console()\n",
        "    table = Table(\n",
        "        Column(\"source_text\", justify=\"center\"),\n",
        "        Column(\"target_text\", justify=\"center\"),\n",
        "        title=\"Sample Data\",\n",
        "        pad_edge=False,\n",
        "        box=box.ASCII,\n",
        "    )\n",
        "\n",
        "    for i, row in enumerate(df.values.tolist()):\n",
        "        table.add_row(row[0], row[1])\n",
        "\n",
        "    console.print(table)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFOWkCY_6fcS"
      },
      "source": [
        "### Training logger to log training progress"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aU4giiXw3wC_"
      },
      "source": [
        "training_logger = Table(\n",
        "    Column(\"Epoch\", justify=\"center\"),\n",
        "    Column(\"Steps\", justify=\"center\"),\n",
        "    Column(\"Loss\", justify=\"center\"),\n",
        "    title=\"Training Status\",\n",
        "    pad_edge=False,\n",
        "    box=box.ASCII,\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlE3YDK46EwA"
      },
      "source": [
        "### Read the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "yUWCAshf3AEU",
        "outputId": "8c5ddca2-e1db-49c1-8ffe-37ca32e57d96"
      },
      "source": [
        "path = \"https://raw.githubusercontent.com/Shivanandroy/T5-Finetuning-PyTorch/main/data/news_summary.csv\"\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headlines</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
              "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
              "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
              "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
              "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
              "      <td>Speaking about the sexual harassment allegatio...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           headlines                                               text\n",
              "0  upGrad learner switches to career in ML & Al w...  Saurav Kant, an alumnus of upGrad and IIIT-B's...\n",
              "1  Delhi techie wins free food from Swiggy for on...  Kunal Shah's credit card bill payment platform...\n",
              "2  New Zealand end Rohit Sharma-led India's 12-ma...  New Zealand defeated India by 8 wickets in the...\n",
              "3  Aegon life iTerm insurance plan helps customer...  With Aegon Life iTerm Insurance plan, customer...\n",
              "4  Have known Hirani for yrs, what if MeToo claim...  Speaking about the sexual harassment allegatio..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "eS9AXq8k3Zbp",
        "outputId": "21edb2dc-348a-4f81-b34e-f4424d08fed8"
      },
      "source": [
        "df"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headlines</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
              "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
              "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
              "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
              "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
              "      <td>Speaking about the sexual harassment allegatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98396</th>\n",
              "      <td>CRPF jawan axed to death by Maoists in Chhatti...</td>\n",
              "      <td>A CRPF jawan was on Tuesday axed to death with...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98397</th>\n",
              "      <td>First song from Sonakshi Sinha's 'Noor' titled...</td>\n",
              "      <td>'Uff Yeh', the first song from the Sonakshi Si...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98398</th>\n",
              "      <td>'The Matrix' film to get a reboot: Reports</td>\n",
              "      <td>According to reports, a new version of the 199...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98399</th>\n",
              "      <td>Snoop Dogg aims gun at clown dressed as Trump ...</td>\n",
              "      <td>A new music video shows rapper Snoop Dogg aimi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98400</th>\n",
              "      <td>Madhesi Morcha withdraws support to Nepalese g...</td>\n",
              "      <td>Madhesi Morcha, an alliance of seven political...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>98401 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               headlines                                               text\n",
              "0      upGrad learner switches to career in ML & Al w...  Saurav Kant, an alumnus of upGrad and IIIT-B's...\n",
              "1      Delhi techie wins free food from Swiggy for on...  Kunal Shah's credit card bill payment platform...\n",
              "2      New Zealand end Rohit Sharma-led India's 12-ma...  New Zealand defeated India by 8 wickets in the...\n",
              "3      Aegon life iTerm insurance plan helps customer...  With Aegon Life iTerm Insurance plan, customer...\n",
              "4      Have known Hirani for yrs, what if MeToo claim...  Speaking about the sexual harassment allegatio...\n",
              "...                                                  ...                                                ...\n",
              "98396  CRPF jawan axed to death by Maoists in Chhatti...  A CRPF jawan was on Tuesday axed to death with...\n",
              "98397  First song from Sonakshi Sinha's 'Noor' titled...  'Uff Yeh', the first song from the Sonakshi Si...\n",
              "98398         'The Matrix' film to get a reboot: Reports  According to reports, a new version of the 199...\n",
              "98399  Snoop Dogg aims gun at clown dressed as Trump ...  A new music video shows rapper Snoop Dogg aimi...\n",
              "98400  Madhesi Morcha withdraws support to Nepalese g...  Madhesi Morcha, an alliance of seven political...\n",
              "\n",
              "[98401 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "VI4sfaGaAhJ0",
        "outputId": "0946a206-ce35-448f-eccd-a14c61f81f8d"
      },
      "source": [
        "df = df[:1000]\n",
        "df"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headlines</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
              "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
              "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
              "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
              "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
              "      <td>Speaking about the sexual harassment allegatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>Aamir's 'Rubaru Roshni' screened for Sri Sri R...</td>\n",
              "      <td>Aamir Khan screened his upcoming short film 'R...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>Playing Meena Thackeray was an honour: Amrita ...</td>\n",
              "      <td>Amrita Rao, who plays Bal Thackeray's wife Mee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>Won't apologise: Kangana on Karni Sena's threa...</td>\n",
              "      <td>Kangana Ranaut, who was threatened by the Karn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>Wonderful, humbling feeling: Anupam on meeting...</td>\n",
              "      <td>Sharing a picture with US talk show host Jimmy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>Erotic drawing by late rapper Tupac sold for $...</td>\n",
              "      <td>An erotic drawing by late rapper Tupac Shakur ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             headlines                                               text\n",
              "0    upGrad learner switches to career in ML & Al w...  Saurav Kant, an alumnus of upGrad and IIIT-B's...\n",
              "1    Delhi techie wins free food from Swiggy for on...  Kunal Shah's credit card bill payment platform...\n",
              "2    New Zealand end Rohit Sharma-led India's 12-ma...  New Zealand defeated India by 8 wickets in the...\n",
              "3    Aegon life iTerm insurance plan helps customer...  With Aegon Life iTerm Insurance plan, customer...\n",
              "4    Have known Hirani for yrs, what if MeToo claim...  Speaking about the sexual harassment allegatio...\n",
              "..                                                 ...                                                ...\n",
              "995  Aamir's 'Rubaru Roshni' screened for Sri Sri R...  Aamir Khan screened his upcoming short film 'R...\n",
              "996  Playing Meena Thackeray was an honour: Amrita ...  Amrita Rao, who plays Bal Thackeray's wife Mee...\n",
              "997  Won't apologise: Kangana on Karni Sena's threa...  Kangana Ranaut, who was threatened by the Karn...\n",
              "998  Wonderful, humbling feeling: Anupam on meeting...  Sharing a picture with US talk show host Jimmy...\n",
              "999  Erotic drawing by late rapper Tupac sold for $...  An erotic drawing by late rapper Tupac Shakur ...\n",
              "\n",
              "[1000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWYvvDT56QOd"
      },
      "source": [
        "### Setting up the device for GPU usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nE0hH71S3zgu",
        "outputId": "8a597afe-d4ca-4352-f68a-2e5f4afdd039"
      },
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcif3De268qx"
      },
      "source": [
        "### Creating a CustomDataset\n",
        "\n",
        "This class will take 6 arguments as input:\n",
        "\n",
        "- dataframe (pandas.DataFrame): Input dataframe\n",
        "- tokenizer (transformers.tokenizer): T5 tokenizer\n",
        "- source_len (int): Max length of source text\n",
        "- target_len (int): Max length of target text\n",
        "- source_text (str): column name of source text\n",
        "- target_text (str) : column name of target text\n",
        "\n",
        "This class will have 2 methods:\n",
        "\n",
        "- __len__: returns the length of the dataframe\n",
        "- __getitem__: return the input ids, attention masks and target ids"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-NO58gz32w-"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Creating a custom dataset for reading the dataset and\n",
        "    loading it into the dataloader to pass it to the\n",
        "    neural network for finetuning the model\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, dataframe, tokenizer, source_len, target_len, source_text, target_text\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initializes a Dataset class\n",
        "\n",
        "        Args:\n",
        "            dataframe (pandas.DataFrame): Input dataframe\n",
        "            tokenizer (transformers.tokenizer): Transformers tokenizer\n",
        "            source_len (int): Max length of source text\n",
        "            target_len (int): Max length of target text\n",
        "            source_text (str): column name of source text\n",
        "            target_text (str): column name of target text\n",
        "        \"\"\"\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.source_len = source_len\n",
        "        self.summ_len = target_len\n",
        "        self.target_text = self.data[target_text]\n",
        "        self.source_text = self.data[source_text]\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"returns the length of dataframe\"\"\"\n",
        "\n",
        "        return len(self.target_text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"return the input ids, attention masks and target ids\"\"\"\n",
        "\n",
        "        source_text = str(self.source_text[index])\n",
        "        target_text = str(self.target_text[index])\n",
        "\n",
        "        # cleaning data so as to ensure data is in string type\n",
        "        source_text = \" \".join(source_text.split())\n",
        "        target_text = \" \".join(target_text.split())\n",
        "\n",
        "        source = self.tokenizer.batch_encode_plus(\n",
        "            [source_text],\n",
        "            max_length=self.source_len,\n",
        "            pad_to_max_length=True,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        target = self.tokenizer.batch_encode_plus(\n",
        "            [target_text],\n",
        "            max_length=self.summ_len,\n",
        "            pad_to_max_length=True,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        source_ids = source[\"input_ids\"].squeeze()\n",
        "        source_mask = source[\"attention_mask\"].squeeze()\n",
        "        target_ids = target[\"input_ids\"].squeeze()\n",
        "        target_mask = target[\"attention_mask\"].squeeze()\n",
        "\n",
        "        return {\n",
        "            \"source_ids\": source_ids.to(dtype=torch.long),\n",
        "            \"source_mask\": source_mask.to(dtype=torch.long),\n",
        "            \"target_ids\": target_ids.to(dtype=torch.long),\n",
        "            \"target_ids_y\": target_ids.to(dtype=torch.long),\n",
        "        }"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ae0vg54_7Gug"
      },
      "source": [
        "### Train function\n",
        "This will take 6 arguments as input:\n",
        "\n",
        "- epoch: epoch\n",
        "- tokenizer: T5 tokenizer\n",
        "- model: T5 model\n",
        "- loader: Train Dataloader\n",
        "- optimizer: Optimizer\n",
        "- device: Device (CUDA / CPU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGlR-0uK4BB4"
      },
      "source": [
        "def train(epoch, tokenizer, model, device, loader, optimizer):\n",
        "\n",
        "    \"\"\"\n",
        "    Function to be called for training with the parameters passed from main function\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    model.train()\n",
        "    for _, data in enumerate(loader, 0):\n",
        "        y = data[\"target_ids\"].to(device, dtype=torch.long)\n",
        "        y_ids = y[:, :-1].contiguous()\n",
        "        lm_labels = y[:, 1:].clone().detach()\n",
        "        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
        "        ids = data[\"source_ids\"].to(device, dtype=torch.long)\n",
        "        mask = data[\"source_mask\"].to(device, dtype=torch.long)\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=ids,\n",
        "            attention_mask=mask,\n",
        "            decoder_input_ids=y_ids,\n",
        "            labels=lm_labels,\n",
        "        )\n",
        "        loss = outputs[0]\n",
        "\n",
        "        if _ % 10 == 0:\n",
        "            training_logger.add_row(str(epoch), str(_), str(loss))\n",
        "            console.print(training_logger)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUCPKFxC4F5i"
      },
      "source": [
        "def validate(epoch, tokenizer, model, device, loader):\n",
        "\n",
        "  \"\"\"\n",
        "  Function to evaluate model for predictions\n",
        "\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "  predictions = []\n",
        "  actuals = []\n",
        "  with torch.no_grad():\n",
        "      for _, data in enumerate(loader, 0):\n",
        "          y = data['target_ids'].to(device, dtype = torch.long)\n",
        "          ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "          mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "          generated_ids = model.generate(\n",
        "              input_ids = ids,\n",
        "              attention_mask = mask, \n",
        "              max_length=150, \n",
        "              num_beams=2,\n",
        "              repetition_penalty=2.5, \n",
        "              length_penalty=1.0, \n",
        "              early_stopping=True\n",
        "              )\n",
        "          preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
        "          target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n",
        "          if _%10==0:\n",
        "              console.print(f'Completed {_}')\n",
        "\n",
        "          predictions.extend(preds)\n",
        "          actuals.extend(target)\n",
        "  return predictions, actuals"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYYAmtSp7uzh"
      },
      "source": [
        "### T5 Trainer\n",
        "\n",
        "T5Trainer will have 5 arguments:\n",
        "\n",
        "- dataframe: Input dataframe\n",
        "- source_text: Column name of the input text i.e. article content\n",
        "- target_text: Column name of the taregt text i.e. one line summary\n",
        "- model_params: T5 model parameters\n",
        "- output_dir: Output directory to save fine tuned T5 model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQCxDQgr4JBm"
      },
      "source": [
        "def T5Trainer(\n",
        "    dataframe, source_text, target_text, model_params, output_dir=\"./outputs/\"\n",
        "):\n",
        "\n",
        "    \"\"\"\n",
        "    T5 trainer\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Set random seeds and deterministic pytorch for reproducibility\n",
        "    torch.manual_seed(model_params[\"SEED\"])  # pytorch random seed\n",
        "    np.random.seed(model_params[\"SEED\"])  # numpy random seed\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "    # logging\n",
        "    console.log(f\"\"\"[Model]: Loading {model_params[\"MODEL\"]}...\\n\"\"\")\n",
        "\n",
        "    # tokenzier for encoding the text\n",
        "    tokenizer = T5Tokenizer.from_pretrained(model_params[\"MODEL\"])\n",
        "\n",
        "    # Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary.\n",
        "    # Further this model is sent to device (GPU/TPU) for using the hardware.\n",
        "    model = T5ForConditionalGeneration.from_pretrained(model_params[\"MODEL\"])\n",
        "    model = model.to(device)\n",
        "\n",
        "    # logging\n",
        "    console.log(f\"[Data]: Reading data...\\n\")\n",
        "\n",
        "    # Importing the raw dataset\n",
        "    dataframe = dataframe[[source_text, target_text]]\n",
        "    display_df(dataframe.head(2))\n",
        "\n",
        "    # Creation of Dataset and Dataloader\n",
        "    # Defining the train size. So 80% of the data will be used for training and the rest for validation.\n",
        "    train_size = 0.8\n",
        "    train_dataset = dataframe.sample(frac=train_size, random_state=model_params[\"SEED\"])\n",
        "    val_dataset = dataframe.drop(train_dataset.index).reset_index(drop=True)\n",
        "    train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "    console.print(f\"FULL Dataset: {dataframe.shape}\")\n",
        "    console.print(f\"TRAIN Dataset: {train_dataset.shape}\")\n",
        "    console.print(f\"TEST Dataset: {val_dataset.shape}\\n\")\n",
        "\n",
        "    # Creating the Training and Validation dataset for further creation of Dataloader\n",
        "    training_set = CustomDataset(\n",
        "        train_dataset,\n",
        "        tokenizer,\n",
        "        model_params[\"MAX_SOURCE_TEXT_LENGTH\"],\n",
        "        model_params[\"MAX_TARGET_TEXT_LENGTH\"],\n",
        "        source_text,\n",
        "        target_text,\n",
        "    )\n",
        "    val_set = CustomDataset(\n",
        "        val_dataset,\n",
        "        tokenizer,\n",
        "        model_params[\"MAX_SOURCE_TEXT_LENGTH\"],\n",
        "        model_params[\"MAX_TARGET_TEXT_LENGTH\"],\n",
        "        source_text,\n",
        "        target_text,\n",
        "    )\n",
        "\n",
        "    # Defining the parameters for creation of dataloaders\n",
        "    train_params = {\n",
        "        \"batch_size\": model_params[\"TRAIN_BATCH_SIZE\"],\n",
        "        \"shuffle\": True,\n",
        "        \"num_workers\": 0,\n",
        "    }\n",
        "\n",
        "    val_params = {\n",
        "        \"batch_size\": model_params[\"VALID_BATCH_SIZE\"],\n",
        "        \"shuffle\": False,\n",
        "        \"num_workers\": 0,\n",
        "    }\n",
        "\n",
        "    # Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n",
        "    training_loader = DataLoader(training_set, **train_params)\n",
        "    val_loader = DataLoader(val_set, **val_params)\n",
        "\n",
        "    # Defining the optimizer that will be used to tune the weights of the network in the training session.\n",
        "    optimizer = torch.optim.Adam(\n",
        "        params=model.parameters(), lr=model_params[\"LEARNING_RATE\"]\n",
        "    )\n",
        "\n",
        "    # Training loop\n",
        "    console.log(f\"[Initiating Fine Tuning]...\\n\")\n",
        "\n",
        "    for epoch in range(model_params[\"TRAIN_EPOCHS\"]):\n",
        "        train(epoch, tokenizer, model, device, training_loader, optimizer)\n",
        "\n",
        "    console.log(f\"[Saving Model]...\\n\")\n",
        "    # Saving the model after training\n",
        "    path = os.path.join(output_dir, \"model_files\")\n",
        "    model.save_pretrained(path)\n",
        "    tokenizer.save_pretrained(path)\n",
        "\n",
        "    # evaluating test dataset\n",
        "    console.log(f\"[Initiating Validation]...\\n\")\n",
        "    for epoch in range(model_params[\"VAL_EPOCHS\"]):\n",
        "        predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n",
        "        final_df = pd.DataFrame({\"Generated Text\": predictions, \"Actual Text\": actuals})\n",
        "        final_df.to_csv(os.path.join(output_dir, \"predictions.csv\"))\n",
        "\n",
        "    console.save_text(os.path.join(output_dir, \"logs.txt\"))\n",
        "\n",
        "    console.log(f\"[Validation Completed.]\\n\")\n",
        "    console.print(\n",
        "        f\"\"\"[Model] Model saved @ {os.path.join(output_dir, \"model_files\")}\\n\"\"\"\n",
        "    )\n",
        "    console.print(\n",
        "        f\"\"\"[Validation] Generation on Validation data saved @ {os.path.join(output_dir,'predictions.csv')}\\n\"\"\"\n",
        "    )\n",
        "    console.print(f\"\"\"[Logs] Logs saved @ {os.path.join(output_dir,'logs.txt')}\\n\"\"\")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EV7GxTV78Fn"
      },
      "source": [
        "### Model Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-YI6UtV4OUW"
      },
      "source": [
        "# let's define model parameters specific to T5\n",
        "model_params = {\n",
        "    \"MODEL\": \"t5-base\",  # model_type: t5-base/t5-large\n",
        "    \"TRAIN_BATCH_SIZE\": 8,  # training batch size\n",
        "    \"VALID_BATCH_SIZE\": 8,  # validation batch size\n",
        "    \"TRAIN_EPOCHS\": 3,  # number of training epochs\n",
        "    \"VAL_EPOCHS\": 1,  # number of validation epochs\n",
        "    \"LEARNING_RATE\": 1e-4,  # learning rate\n",
        "    \"MAX_SOURCE_TEXT_LENGTH\": 512,  # max length of source text\n",
        "    \"MAX_TARGET_TEXT_LENGTH\": 50,  # max length of target text\n",
        "    \"SEED\": 42,  # set seed for reproducibility\n",
        "}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1BtV8Jad4Rxf",
        "outputId": "6c0c5480-4bba-4f7c-ae37-8c7a2738c9a2"
      },
      "source": [
        "# T5 accepts prefix of the task to be performed:\n",
        "# Since we are summarizing, let's add summarize to source text as a prefix\n",
        "df[\"text\"] = \"summarize: \" + df[\"text\"]\n",
        "\n",
        "T5Trainer(\n",
        "    dataframe=df[:5000],\n",
        "    source_text=\"text\",\n",
        "    target_text=\"headlines\",\n",
        "    model_params=model_params,\n",
        "    output_dir=\"outputs\",\n",
        ")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:32:13] </span><span style=\"font-weight: bold\">[</span>Model<span style=\"font-weight: bold\">]</span>: Loading t5-base<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-20-69ba19ca9a26&gt;:16</span>\n",
              "                                                                                             \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[16:32:13]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mModel\u001b[1m]\u001b[0m: Loading t5-base\u001b[33m...\u001b[0m                     \u001b[2m<ipython-input-20-69ba19ca9a26>\u001b[0m\u001b[2m:16\u001b[0m\n",
              "                                                                                             \n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:32:16] </span><span style=\"font-weight: bold\">[</span>Data<span style=\"font-weight: bold\">]</span>: Reading data<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-20-69ba19ca9a26&gt;:27</span>\n",
              "                                                                                             \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[16:32:16]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mData\u001b[1m]\u001b[0m: Reading data\u001b[33m...\u001b[0m                         \u001b[2m<ipython-input-20-69ba19ca9a26>\u001b[0m\u001b[2m:27\u001b[0m\n",
              "                                                                                             \n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                         Sample Data                                         </span>\n",
              "+-------------------------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">                source_text                  </span>|<span style=\"font-weight: bold\">                 target_text                 </span>|\n",
              "|---------------------------------------------+---------------------------------------------|\n",
              "|  summarize: summarize: summarize: Saurav    | upGrad learner switches to career in ML &amp; Al|\n",
              "| Kant, an alumnus of upGrad and IIIT-B's PG  |             with 90% salary hike            |\n",
              "| Program in Machine learning and Artificial  |                                             |\n",
              "| Intelligence, was a Sr Systems Engineer at  |                                             |\n",
              "|    Infosys with almost 5 years of work      |                                             |\n",
              "|    experience. The program and upGrad's     |                                             |\n",
              "|    360-degree career support helped him     |                                             |\n",
              "|   transition to a Data Scientist at Tech    |                                             |\n",
              "|  Mahindra with 90% salary hike. upGrad's    |                                             |\n",
              "| Online Power Learning has powered 3 lakh+   |                                             |\n",
              "|                  careers.                   |                                             |\n",
              "|   summarize: summarize: summarize: Kunal    | Delhi techie wins free food from Swiggy for |\n",
              "| Shah's credit card bill payment platform,   |               one year on CRED              |\n",
              "| CRED, gave users a chance to win free food  |                                             |\n",
              "|from Swiggy for one year. Pranav Kaushik, a  |                                             |\n",
              "|   Delhi techie, bagged this reward after    |                                             |\n",
              "|spending 2000 CRED coins. Users get one CRED |                                             |\n",
              "| coin per rupee of bill paid, which can be   |                                             |\n",
              "|   used to avail rewards from brands like    |                                             |\n",
              "| Ixigo, BookMyShow, UberEats, Cult.Fit and   |                                             |\n",
              "|                   more.                     |                                             |\n",
              "+-------------------------------------------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                                         Sample Data                                         \u001b[0m\n",
              "+-------------------------------------------------------------------------------------------+\n",
              "|\u001b[1m                source_text                 \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                target_text                 \u001b[0m|\n",
              "|---------------------------------------------+---------------------------------------------|\n",
              "|  summarize: summarize: summarize: Saurav    | upGrad learner switches to career in ML & Al|\n",
              "| Kant, an alumnus of upGrad and IIIT-B's PG  |             with 90% salary hike            |\n",
              "| Program in Machine learning and Artificial  |                                             |\n",
              "| Intelligence, was a Sr Systems Engineer at  |                                             |\n",
              "|    Infosys with almost 5 years of work      |                                             |\n",
              "|    experience. The program and upGrad's     |                                             |\n",
              "|    360-degree career support helped him     |                                             |\n",
              "|   transition to a Data Scientist at Tech    |                                             |\n",
              "|  Mahindra with 90% salary hike. upGrad's    |                                             |\n",
              "| Online Power Learning has powered 3 lakh+   |                                             |\n",
              "|                  careers.                   |                                             |\n",
              "|   summarize: summarize: summarize: Kunal    | Delhi techie wins free food from Swiggy for |\n",
              "| Shah's credit card bill payment platform,   |               one year on CRED              |\n",
              "| CRED, gave users a chance to win free food  |                                             |\n",
              "|from Swiggy for one year. Pranav Kaushik, a  |                                             |\n",
              "|   Delhi techie, bagged this reward after    |                                             |\n",
              "|spending 2000 CRED coins. Users get one CRED |                                             |\n",
              "| coin per rupee of bill paid, which can be   |                                             |\n",
              "|   used to avail rewards from brands like    |                                             |\n",
              "| Ixigo, BookMyShow, UberEats, Cult.Fit and   |                                             |\n",
              "|                   more.                     |                                             |\n",
              "+-------------------------------------------------------------------------------------------+\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">FULL Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "FULL Dataset: \u001b[1m(\u001b[0m\u001b[1;36m1000\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TRAIN Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "TRAIN Dataset: \u001b[1m(\u001b[0m\u001b[1;36m800\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TEST Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">200</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "TEST Dataset: \u001b[1m(\u001b[0m\u001b[1;36m200\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n",
              "\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">[</span>Initiating Fine Tuning<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-20-69ba19ca9a26&gt;:85</span>\n",
              "                                                                                             \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mInitiating Fine Tuning\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m                     \u001b[2m<ipython-input-20-69ba19ca9a26>\u001b[0m\u001b[2m:85\u001b[0m\n",
              "                                                                                             \n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n",
              "+--------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "+--------------------------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                              Training Status                               \u001b[0m\n",
              "+--------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "+--------------------------------------------------------------------------+\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n",
              "+--------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "+--------------------------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                              Training Status                               \u001b[0m\n",
              "+--------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "+--------------------------------------------------------------------------+\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n",
              "+--------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "+--------------------------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                              Training Status                               \u001b[0m\n",
              "+--------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "+--------------------------------------------------------------------------+\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n",
              "+--------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "+--------------------------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                              Training Status                               \u001b[0m\n",
              "+--------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "+--------------------------------------------------------------------------+\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n",
              "+--------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "+--------------------------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                              Training Status                               \u001b[0m\n",
              "+--------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "+--------------------------------------------------------------------------+\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n",
              "+--------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "+--------------------------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                              Training Status                               \u001b[0m\n",
              "+--------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "+--------------------------------------------------------------------------+\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n",
              "+--------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "+--------------------------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                              Training Status                               \u001b[0m\n",
              "+--------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "+--------------------------------------------------------------------------+\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n",
              "+--------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "+--------------------------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                              Training Status                               \u001b[0m\n",
              "+--------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "+--------------------------------------------------------------------------+\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n",
              "+--------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "+--------------------------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                              Training Status                               \u001b[0m\n",
              "+--------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "+--------------------------------------------------------------------------+\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n",
              "+--------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "+--------------------------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                              Training Status                               \u001b[0m\n",
              "+--------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "+--------------------------------------------------------------------------+\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n",
              "+--------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "+--------------------------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                              Training Status                               \u001b[0m\n",
              "+--------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "+--------------------------------------------------------------------------+\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n",
              "+--------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "+--------------------------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                              Training Status                               \u001b[0m\n",
              "+--------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "+--------------------------------------------------------------------------+\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n",
              "+--------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "+--------------------------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                              Training Status                               \u001b[0m\n",
              "+--------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "+--------------------------------------------------------------------------+\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n",
              "+--------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  30   | tensor(1.3172, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "+--------------------------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                              Training Status                               \u001b[0m\n",
              "+--------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  30   | tensor(1.3172, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "+--------------------------------------------------------------------------+\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n",
              "+--------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  30   | tensor(1.3172, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  40   | tensor(1.4199, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "+--------------------------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                              Training Status                               \u001b[0m\n",
              "+--------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  30   | tensor(1.3172, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  40   | tensor(1.4199, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "+--------------------------------------------------------------------------+\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n",
              "+--------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  30   | tensor(1.3172, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  40   | tensor(1.4199, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  50   | tensor(2.1207, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "+--------------------------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                              Training Status                               \u001b[0m\n",
              "+--------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  30   | tensor(1.3172, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  40   | tensor(1.4199, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  50   | tensor(2.1207, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "+--------------------------------------------------------------------------+\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n",
              "+--------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  30   | tensor(1.3172, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  40   | tensor(1.4199, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  50   | tensor(2.1207, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  60   | tensor(1.7282, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "+--------------------------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                              Training Status                               \u001b[0m\n",
              "+--------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  30   | tensor(1.3172, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  40   | tensor(1.4199, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  50   | tensor(2.1207, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  60   | tensor(1.7282, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "+--------------------------------------------------------------------------+\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n",
              "+--------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  30   | tensor(1.3172, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  40   | tensor(1.4199, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  50   | tensor(2.1207, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  60   | tensor(1.7282, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  70   | tensor(1.5816, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "+--------------------------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                              Training Status                               \u001b[0m\n",
              "+--------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  30   | tensor(1.3172, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  40   | tensor(1.4199, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  50   | tensor(2.1207, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  60   | tensor(1.7282, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  70   | tensor(1.5816, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "+--------------------------------------------------------------------------+\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n",
              "+--------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  30   | tensor(1.3172, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  40   | tensor(1.4199, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  50   | tensor(2.1207, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  60   | tensor(1.7282, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  70   | tensor(1.5816, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  80   | tensor(1.3366, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "+--------------------------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                              Training Status                               \u001b[0m\n",
              "+--------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  30   | tensor(1.3172, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  40   | tensor(1.4199, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  50   | tensor(2.1207, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  60   | tensor(1.7282, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  70   | tensor(1.5816, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  80   | tensor(1.3366, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "+--------------------------------------------------------------------------+\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n",
              "+--------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  30   | tensor(1.3172, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  40   | tensor(1.4199, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  50   | tensor(2.1207, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  60   | tensor(1.7282, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  70   | tensor(1.5816, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  80   | tensor(1.3366, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  90   | tensor(2.0918, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "+--------------------------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                              Training Status                               \u001b[0m\n",
              "+--------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  30   | tensor(1.3172, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  40   | tensor(1.4199, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  50   | tensor(2.1207, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  60   | tensor(1.7282, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  70   | tensor(1.5816, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  80   | tensor(1.3366, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  90   | tensor(2.0918, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "+--------------------------------------------------------------------------+\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n",
              "+--------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  30   | tensor(1.3172, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  40   | tensor(1.4199, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  50   | tensor(2.1207, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  60   | tensor(1.7282, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  70   | tensor(1.5816, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  80   | tensor(1.3366, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  90   | tensor(2.0918, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |   0   | tensor(1.2743, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "+--------------------------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                              Training Status                               \u001b[0m\n",
              "+--------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  30   | tensor(1.3172, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  40   | tensor(1.4199, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  50   | tensor(2.1207, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  60   | tensor(1.7282, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  70   | tensor(1.5816, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  80   | tensor(1.3366, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  90   | tensor(2.0918, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |   0   | tensor(1.2743, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "+--------------------------------------------------------------------------+\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n",
              "+--------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  30   | tensor(1.3172, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  40   | tensor(1.4199, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  50   | tensor(2.1207, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  60   | tensor(1.7282, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  70   | tensor(1.5816, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  80   | tensor(1.3366, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  90   | tensor(2.0918, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |   0   | tensor(1.2743, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  10   | tensor(1.4041, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "+--------------------------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                              Training Status                               \u001b[0m\n",
              "+--------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  30   | tensor(1.3172, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  40   | tensor(1.4199, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  50   | tensor(2.1207, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  60   | tensor(1.7282, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  70   | tensor(1.5816, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  80   | tensor(1.3366, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  90   | tensor(2.0918, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |   0   | tensor(1.2743, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  10   | tensor(1.4041, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "+--------------------------------------------------------------------------+\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n",
              "+--------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  30   | tensor(1.3172, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  40   | tensor(1.4199, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  50   | tensor(2.1207, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  60   | tensor(1.7282, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  70   | tensor(1.5816, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  80   | tensor(1.3366, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  90   | tensor(2.0918, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |   0   | tensor(1.2743, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  10   | tensor(1.4041, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  20   | tensor(1.0578, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "+--------------------------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                              Training Status                               \u001b[0m\n",
              "+--------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  30   | tensor(1.3172, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  40   | tensor(1.4199, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  50   | tensor(2.1207, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  60   | tensor(1.7282, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  70   | tensor(1.5816, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  80   | tensor(1.3366, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  90   | tensor(2.0918, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |   0   | tensor(1.2743, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  10   | tensor(1.4041, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  20   | tensor(1.0578, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "+--------------------------------------------------------------------------+\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n",
              "+--------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  30   | tensor(1.3172, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  40   | tensor(1.4199, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  50   | tensor(2.1207, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  60   | tensor(1.7282, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  70   | tensor(1.5816, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  80   | tensor(1.3366, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  90   | tensor(2.0918, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |   0   | tensor(1.2743, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  10   | tensor(1.4041, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  20   | tensor(1.0578, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  30   | tensor(1.0989, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "+--------------------------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                              Training Status                               \u001b[0m\n",
              "+--------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  30   | tensor(1.3172, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  40   | tensor(1.4199, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  50   | tensor(2.1207, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  60   | tensor(1.7282, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  70   | tensor(1.5816, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  80   | tensor(1.3366, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  90   | tensor(2.0918, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |   0   | tensor(1.2743, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  10   | tensor(1.4041, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  20   | tensor(1.0578, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  30   | tensor(1.0989, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "+--------------------------------------------------------------------------+\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n",
              "+--------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  30   | tensor(1.3172, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  40   | tensor(1.4199, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  50   | tensor(2.1207, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  60   | tensor(1.7282, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  70   | tensor(1.5816, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  80   | tensor(1.3366, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  90   | tensor(2.0918, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |   0   | tensor(1.2743, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  10   | tensor(1.4041, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  20   | tensor(1.0578, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  30   | tensor(1.0989, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  40   | tensor(1.4865, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "+--------------------------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                              Training Status                               \u001b[0m\n",
              "+--------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  30   | tensor(1.3172, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  40   | tensor(1.4199, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  50   | tensor(2.1207, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  60   | tensor(1.7282, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  70   | tensor(1.5816, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  80   | tensor(1.3366, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  90   | tensor(2.0918, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |   0   | tensor(1.2743, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  10   | tensor(1.4041, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  20   | tensor(1.0578, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  30   | tensor(1.0989, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  40   | tensor(1.4865, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "+--------------------------------------------------------------------------+\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n",
              "+--------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  30   | tensor(1.3172, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  40   | tensor(1.4199, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  50   | tensor(2.1207, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  60   | tensor(1.7282, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  70   | tensor(1.5816, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  80   | tensor(1.3366, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  90   | tensor(2.0918, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |   0   | tensor(1.2743, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  10   | tensor(1.4041, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  20   | tensor(1.0578, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  30   | tensor(1.0989, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  40   | tensor(1.4865, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  50   | tensor(0.9826, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "+--------------------------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                              Training Status                               \u001b[0m\n",
              "+--------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  30   | tensor(1.3172, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  40   | tensor(1.4199, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  50   | tensor(2.1207, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  60   | tensor(1.7282, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  70   | tensor(1.5816, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  80   | tensor(1.3366, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  90   | tensor(2.0918, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |   0   | tensor(1.2743, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  10   | tensor(1.4041, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  20   | tensor(1.0578, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  30   | tensor(1.0989, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  40   | tensor(1.4865, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  50   | tensor(0.9826, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "+--------------------------------------------------------------------------+\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n",
              "+--------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  30   | tensor(1.3172, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  40   | tensor(1.4199, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  50   | tensor(2.1207, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  60   | tensor(1.7282, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  70   | tensor(1.5816, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  80   | tensor(1.3366, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  90   | tensor(2.0918, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |   0   | tensor(1.2743, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  10   | tensor(1.4041, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  20   | tensor(1.0578, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  30   | tensor(1.0989, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  40   | tensor(1.4865, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  50   | tensor(0.9826, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  60   | tensor(1.3455, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "+--------------------------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                              Training Status                               \u001b[0m\n",
              "+--------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  30   | tensor(1.3172, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  40   | tensor(1.4199, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  50   | tensor(2.1207, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  60   | tensor(1.7282, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  70   | tensor(1.5816, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  80   | tensor(1.3366, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  90   | tensor(2.0918, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |   0   | tensor(1.2743, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  10   | tensor(1.4041, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  20   | tensor(1.0578, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  30   | tensor(1.0989, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  40   | tensor(1.4865, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  50   | tensor(0.9826, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  60   | tensor(1.3455, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "+--------------------------------------------------------------------------+\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n",
              "+--------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  30   | tensor(1.3172, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  40   | tensor(1.4199, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  50   | tensor(2.1207, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  60   | tensor(1.7282, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  70   | tensor(1.5816, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  80   | tensor(1.3366, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  90   | tensor(2.0918, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |   0   | tensor(1.2743, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  10   | tensor(1.4041, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  20   | tensor(1.0578, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  30   | tensor(1.0989, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  40   | tensor(1.4865, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  50   | tensor(0.9826, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  60   | tensor(1.3455, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  70   | tensor(0.7034, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "+--------------------------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                              Training Status                               \u001b[0m\n",
              "+--------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  30   | tensor(1.3172, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  40   | tensor(1.4199, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  50   | tensor(2.1207, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  60   | tensor(1.7282, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  70   | tensor(1.5816, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  80   | tensor(1.3366, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  90   | tensor(2.0918, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |   0   | tensor(1.2743, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  10   | tensor(1.4041, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  20   | tensor(1.0578, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  30   | tensor(1.0989, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  40   | tensor(1.4865, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  50   | tensor(0.9826, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  60   | tensor(1.3455, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  70   | tensor(0.7034, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "+--------------------------------------------------------------------------+\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n",
              "+--------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  30   | tensor(1.3172, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  40   | tensor(1.4199, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  50   | tensor(2.1207, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  60   | tensor(1.7282, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  70   | tensor(1.5816, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  80   | tensor(1.3366, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  90   | tensor(2.0918, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |   0   | tensor(1.2743, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  10   | tensor(1.4041, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  20   | tensor(1.0578, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  30   | tensor(1.0989, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  40   | tensor(1.4865, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  50   | tensor(0.9826, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  60   | tensor(1.3455, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  70   | tensor(0.7034, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  80   | tensor(1.3811, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "+--------------------------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                              Training Status                               \u001b[0m\n",
              "+--------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  30   | tensor(1.3172, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  40   | tensor(1.4199, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  50   | tensor(2.1207, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  60   | tensor(1.7282, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  70   | tensor(1.5816, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  80   | tensor(1.3366, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  90   | tensor(2.0918, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |   0   | tensor(1.2743, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  10   | tensor(1.4041, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  20   | tensor(1.0578, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  30   | tensor(1.0989, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  40   | tensor(1.4865, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  50   | tensor(0.9826, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  60   | tensor(1.3455, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  70   | tensor(0.7034, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  80   | tensor(1.3811, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "+--------------------------------------------------------------------------+\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n",
              "+--------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  30   | tensor(1.3172, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  40   | tensor(1.4199, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  50   | tensor(2.1207, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  60   | tensor(1.7282, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  70   | tensor(1.5816, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  80   | tensor(1.3366, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  1   |  90   | tensor(2.0918, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |   0   | tensor(1.2743, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  10   | tensor(1.4041, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  20   | tensor(1.0578, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  30   | tensor(1.0989, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  40   | tensor(1.4865, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  50   | tensor(0.9826, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  60   | tensor(1.3455, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  70   | tensor(0.7034, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  80   | tensor(1.3811, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "|  2   |  90   | tensor(1.1641, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n",
              "+--------------------------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                              Training Status                               \u001b[0m\n",
              "+--------------------------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n",
              "|------+-------+-----------------------------------------------------------|\n",
              "|  0   |   0   | tensor(6.2116, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  10   | tensor(3.6528, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  20   | tensor(2.9823, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  30   | tensor(2.9011, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  40   | tensor(2.8022, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  50   | tensor(2.7054, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  60   | tensor(2.2910, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  70   | tensor(2.1544, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  80   | tensor(2.2521, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  0   |  90   | tensor(1.8058, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |   0   | tensor(1.4539, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  10   | tensor(1.5739, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  20   | tensor(1.6723, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  30   | tensor(1.3172, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  40   | tensor(1.4199, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  50   | tensor(2.1207, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  60   | tensor(1.7282, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  70   | tensor(1.5816, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  80   | tensor(1.3366, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  1   |  90   | tensor(2.0918, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |   0   | tensor(1.2743, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  10   | tensor(1.4041, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  20   | tensor(1.0578, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  30   | tensor(1.0989, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  40   | tensor(1.4865, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  50   | tensor(0.9826, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  60   | tensor(1.3455, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  70   | tensor(0.7034, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  80   | tensor(1.3811, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "|  2   |  90   | tensor(1.1641, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
              "+--------------------------------------------------------------------------+\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:37:42] </span><span style=\"font-weight: bold\">[</span>Saving Model<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-20-69ba19ca9a26&gt;:90</span>\n",
              "                                                                                             \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[16:37:42]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mSaving Model\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m                               \u001b[2m<ipython-input-20-69ba19ca9a26>\u001b[0m\u001b[2m:90\u001b[0m\n",
              "                                                                                             \n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:37:46] </span><span style=\"font-weight: bold\">[</span>Initiating Validation<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-20-69ba19ca9a26&gt;:97</span>\n",
              "                                                                                             \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[16:37:46]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mInitiating Validation\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m                      \u001b[2m<ipython-input-20-69ba19ca9a26>\u001b[0m\u001b[2m:97\u001b[0m\n",
              "                                                                                             \n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Completed \u001b[1;36m0\u001b[0m\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Completed \u001b[1;36m10\u001b[0m\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Completed \u001b[1;36m20\u001b[0m\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:38:23] </span><span style=\"font-weight: bold\">[</span>Validation Completed.<span style=\"font-weight: bold\">]</span>                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-20-69ba19ca9a26&gt;:105</span>\n",
              "                                                                                             \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[16:38:23]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mValidation Completed.\u001b[1m]\u001b[0m                        \u001b[2m<ipython-input-20-69ba19ca9a26>\u001b[0m\u001b[2m:105\u001b[0m\n",
              "                                                                                             \n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Model<span style=\"font-weight: bold\">]</span> Model saved @ outputs/model_files\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m[\u001b[0mModel\u001b[1m]\u001b[0m Model saved @ outputs/model_files\n",
              "\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Validation<span style=\"font-weight: bold\">]</span> Generation on Validation data saved @ outputs/predictions.csv\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m[\u001b[0mValidation\u001b[1m]\u001b[0m Generation on Validation data saved @ outputs/predictions.csv\n",
              "\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Logs<span style=\"font-weight: bold\">]</span> Logs saved @ outputs/logs.txt\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m[\u001b[0mLogs\u001b[1m]\u001b[0m Logs saved @ outputs/logs.txt\n",
              "\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RGiEMAVBYID"
      },
      "source": [
        "### Homework\n",
        "\n",
        "- Write a prediction function for the summarization task\n",
        "  - Model is already saved @ outputs/model_files\n",
        "  - Load the model\n",
        "  - Prepare the test sample accordingly to feed the model\n",
        "  - Predict on the model\n",
        "  - Collect the output and display the output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_cAitt0BsEZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-TRK9WKBr6O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}